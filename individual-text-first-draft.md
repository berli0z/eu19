Our information diet is increasingly determined by personalisation algorithms, but Facebook prohibits us from understanding how their algorithm processes all of the information they are feeding us. We can’t effectively control what content Facebook decides to show us, and don’t know what content they hide from us.

For instance, if you have hundreds of contacts, yet still repeatedly see content from only 30 friends, you should have a right to know why, as this is effectively a persistent distortion of your reality.

Facebook’s personalisation algorithms influence our priorities, lifestyles, moods, and opinions in an opaque manner regarding both their functioning and objectives. This is what is known as algorithmic hegemony, and the problem is compounded by Facebook’s massive network effect. Suggestions to simply “delete Facebook” if you do not like their practices are impractical when this leads to social isolation.

We should instead consciously build our own algorithms, but not everyone has the knowledge or skills to do so alone. That’s where fbTREX comes in.

With fbTREX, we can better scrutinise our information diets, and get insights into how they present to us different realities. Who is informing us, and about what topics? Are we being provided with misleading information or deceptive advertising?

Promoting algorithmic diversity and our right to pick our own algorithms is a primary goal for fbTREX. We are creating a community where we can share, compare, improve, remix, and critique algorithms, as autonomous and informed individuals deciding what is most appropriate for ourselves at any given time.

By taking ownership over our algorithms, we can explore potential alternatives for social interaction and information sharing. And contrary to Facebook’s practices, we can create algorithms which behave more ethically and transparently, protecting our personal data and prioritizing our own needs.

fbTREX offers two open technology solutions to this end.

A browser extension, which produces a copy of our news feeds by extracting metadata from Facebook’s HTML elements.
This data feeds into a webapp, which creates persistent records of our own news feeds, and visualises our information diet in an accessible manner, enabling us to rewind our news feeds to see personal trends, as well as which friends and networks influence us most, and to compare this with friends.

This will help us to assess how we are using the platform, whether the interaction is productive, and the amount of time we spend on Facebook.

We hope that you will join our digital evidence-gathering community and participate in our efforts to better understand what information the Facebook algorithm is feeding us. The more our community grows, the better we will be able to understand the divergent information diets that Facebook imposes on us. Together we can understand how our different information environments affect us, in particular around important events like elections.

**Privacy**

Dataset access is limited to researchers analyzing collective phenomena in the public interest
1. We will collect only the information that Facebook provides to you in your news feed
2. We will collect only posts marked as public. We will never collect posts marked for friends only.
3. You have full control over your data, and may delete it at any time.
4. No one will have access to your data unless you expressly grant them access. You will have to opt-in to any third-party, including research groups, that you may want to interact with.
5. All research conducted must strictly aim at understanding social phenomena and algorithmic influence, you will never be the subject or object of any study.

**CTA**

Donate your digital body (to science)!
