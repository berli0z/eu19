Facebook’s domination over and proprietisation of information has led to us to a world in which Facebook understands societies better than we understand ourselves.

Facebook has an outsized influence over information sharing, particularly but not only during critical periods like elections. This problem is compounded by another which is only beginning to be understood--that the Facebook algorithm feeds us information based on our existing orientations, reinforcing confirmation biases and polarisation in our societies.

We increasingly lack a common understanding of information. It is as though when you bought a newspaper, the owner of the newsstand were to provide you only the articles they thought you might be interested in, leaving other stories out, meanwhile providing your neighbor with an entirely different newspaper. Facebook creates a bespoke reality for each of us, divergently impacting the lifestyles, moods, and opinions of millions of us on a daily basis.

The problem is not easy to solve. The opaqueness of Facebook and its algorithmic logic has also created issues for regulatory bodies, which cannot regulate platforms whose very functioning is kept secret.

One of fbTREX’s primary goals is to promote algorithmic diversity – to examine how the Facebook algorithm is shaping our informative experiences, and to develop and implement alternatives.

fbTREX provides open technology solutions which produce research-quality datasets useful to researchers interested in discovering, investigating, and addressing the social impacts of Facebook’s algorithmic logic. We hope to foster interdisciplinary cooperation and knowledge-sharing among a growing, global community in the production of evidence-based critiques of the Facebook algorithm based on the perspectives and priorities of people and cultures outside of Palo Alto. So far, studies have primarily focused on the perspectives of US and EU concerns, and we hope to change this trend.

We also hope to this end to facilitate research into issues of algorithmic discrimination and data exploitation, such as reports of advertisers excluding protected groups from seeing their ads through Facebook, and wish to support strategic litigation to this end. This will help us to understand whether regulatory authorities can adequately address issues which arise from algorithmic personalisation and its impacts on our perception and choices.

So far, fbTREX has contributed to research around elections and referendums in 14 countries. We provide a robust infrastructure to support emergent research and experimentation, discovering diverse ways of reusing fbTREX datasets. The time-sensitive, filtered news feed content collected by fbTREX provides empirical evidence for data analysts to study patterns around ongoing observations of the social problems presented by Facebook’s algorithmic hegemony.

Our mandate is not to deliver a single feature or research topic – we hope to engage communities to devise solutions together and develop alternative perspectives on how social networks should work, and how data should be used. fbTREX is ideal for comparing different users’ news feeds based on parameters like gender, political orientation, age, likes, device, etc. But our collected data is only useful to understanding Facebook if it is utilised for research. We hope that you will help us to address the multifaceted issues presented by Facebook’s algorithmic hegemony.

Unlike Facebook, fbTREX prioritises the protection of personal data. Access to the full fbTREX dataset is strictly limited to researchers analyzing collective phenomena in the public interest. We are asking individuals only to share some of the data that Facebook gives them – the goal is to study social media influence, not the subjects participating. Still, this information can contain a lot of personally identifying information (PII). fbTREX’s ethical policy imposes the following limits:
1. We observe only news feeds, not individual profiles or pages.
2. We store only posts marked as “public,” not posts that are restricted to friends.
3. Users who install the extension have full control on their data. They can delete all of the data provided at any time.
4. Third-party access to user data is granted by each user on a case-by-case and strictly opt-in basis.
5. Analyses run on the dataset will be strictly aimed at understanding social phenomenons, not individuals.

CTA forthcoming
